{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30805,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nfrom torchvision import datasets, transforms, models\nfrom torch.utils.data import DataLoader\nfrom tqdm import tqdm\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader, Subset","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-12-05T17:04:50.564797Z","iopub.execute_input":"2024-12-05T17:04:50.565043Z","iopub.status.idle":"2024-12-05T17:04:54.748223Z","shell.execute_reply.started":"2024-12-05T17:04:50.565017Z","shell.execute_reply":"2024-12-05T17:04:54.747301Z"}},"outputs":[],"execution_count":1},{"cell_type":"markdown","source":"# Config","metadata":{}},{"cell_type":"code","source":"batch_size = 64\nnum_classes = 10  # CIFAR-10 has 10 classes\nlearning_rate = 0.001\nnum_epochs = 10\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T17:04:54.749841Z","iopub.execute_input":"2024-12-05T17:04:54.750184Z","iopub.status.idle":"2024-12-05T17:04:54.813544Z","shell.execute_reply.started":"2024-12-05T17:04:54.750158Z","shell.execute_reply":"2024-12-05T17:04:54.812702Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"# Load CIFAR-10 Dataset\ntransform = transforms.Compose([\n    transforms.Resize((224, 224)),  # ResNet-50 expects 224x224 images\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])\ntrain_dataset = datasets.CIFAR10(root=\"data\", train=True, download=True, transform=transform)\ntest_dataset = datasets.CIFAR10(root=\"data\", train=False, download=True, transform=transform)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T17:04:54.814539Z","iopub.execute_input":"2024-12-05T17:04:54.814813Z","iopub.status.idle":"2024-12-05T17:05:03.196002Z","shell.execute_reply.started":"2024-12-05T17:04:54.814787Z","shell.execute_reply":"2024-12-05T17:05:03.194905Z"}},"outputs":[{"name":"stdout","text":"Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to data/cifar-10-python.tar.gz\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 170498071/170498071 [00:04<00:00, 34491078.48it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracting data/cifar-10-python.tar.gz to data\nFiles already downloaded and verified\n","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"# Model","metadata":{}},{"cell_type":"code","source":"%%capture\n# Load Pre-trained ResNet-50 Model\nmodel = models.resnet50(pretrained=True)\nmodel = model.to(device)\n\n# Remove the classifier to extract features\nfeature_extractor = torch.nn.Sequential(*list(model.children())[:-1])  # Remove the last FC layer\nfeature_extractor.eval()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T17:05:03.198108Z","iopub.execute_input":"2024-12-05T17:05:03.198931Z","iopub.status.idle":"2024-12-05T17:05:04.485091Z","shell.execute_reply.started":"2024-12-05T17:05:03.198889Z","shell.execute_reply":"2024-12-05T17:05:04.484133Z"}},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"# Split Dataset","metadata":{}},{"cell_type":"code","source":"def prepare_data(client_id, dataset):\n    # Define label subsets for each client\n    client_labels = {\n        1: [0, 1, 2, 3, 4],         # Airplane, Automobile, Bird, Cat, Deer\n        2: [1, 2, 3, 4, 5, 6, 7, 8],  # Automobile, Bird, Cat, Deer, Dog, Frog, Horse, Ship, Truck\n        3: list(range(10)),          # All classes\n    }\n    \n    labels_for_client = client_labels[client_id]\n\n    # Filter dataset for the client's labels\n    indices = [i for i, (_, label) in enumerate(dataset) if label in labels_for_client]\n    client_dataset = Subset(dataset, indices)\n    return client_dataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T17:05:04.486284Z","iopub.execute_input":"2024-12-05T17:05:04.486975Z","iopub.status.idle":"2024-12-05T17:05:04.492607Z","shell.execute_reply.started":"2024-12-05T17:05:04.486935Z","shell.execute_reply":"2024-12-05T17:05:04.491632Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"client1_data = prepare_data (1 , train_dataset)\nclient2_data = prepare_data (2 , train_dataset)\nclient3_data = prepare_data (3 , train_dataset)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T17:05:04.493726Z","iopub.execute_input":"2024-12-05T17:05:04.494043Z","iopub.status.idle":"2024-12-05T17:07:26.494769Z","shell.execute_reply.started":"2024-12-05T17:05:04.494006Z","shell.execute_reply":"2024-12-05T17:07:26.493837Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"client1_dataloader = DataLoader(client1_data, batch_size=batch_size, shuffle=True)\nclient2_dataloader = DataLoader(client2_data, batch_size=batch_size, shuffle=True)\nclient3_dataloader = DataLoader(client3_data, batch_size=batch_size, shuffle=True)\ntest_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T17:07:26.495935Z","iopub.execute_input":"2024-12-05T17:07:26.496206Z","iopub.status.idle":"2024-12-05T17:07:26.501466Z","shell.execute_reply.started":"2024-12-05T17:07:26.496180Z","shell.execute_reply":"2024-12-05T17:07:26.500421Z"}},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":"# Extract features","metadata":{}},{"cell_type":"code","source":"def extract_features (dataloader) :\n    features = []\n    label_list = []\n    with torch.no_grad():\n        for images, labels in tqdm(dataloader):  # CIFAR-10 labels are not needed for feature extraction\n            images = images.to(device)\n            outputs = feature_extractor(images)  # Extract features\n            outputs = outputs.view(outputs.size(0), -1)  # Flatten the features\n            features.append(outputs.cpu())  # Move to CPU and store\n            label_list.append (labels.cpu ())\n            #print (label_list)\n# Concatenate all features and save\n    features = torch.cat(features, dim=0)\n    label_list = torch.cat (label_list, dim = 0)\n    return features, label_list","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T17:09:53.883649Z","iopub.execute_input":"2024-12-05T17:09:53.884067Z","iopub.status.idle":"2024-12-05T17:09:53.890437Z","shell.execute_reply.started":"2024-12-05T17:09:53.884036Z","shell.execute_reply":"2024-12-05T17:09:53.889356Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"test_image_feature, test_image_label = extract_features (test_dataloader)\nclient1_image_feature, client1_image_label = extract_features (client1_dataloader)\nclient2_image_feature, client2_image_label = extract_features (client2_dataloader)\nclient3_image_feature, client3_image_label = extract_features (client3_dataloader)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T17:09:56.886908Z","iopub.execute_input":"2024-12-05T17:09:56.887593Z","iopub.status.idle":"2024-12-05T17:15:54.800725Z","shell.execute_reply.started":"2024-12-05T17:09:56.887559Z","shell.execute_reply":"2024-12-05T17:15:54.799918Z"}},"outputs":[{"name":"stderr","text":"100%|██████████| 157/157 [00:29<00:00,  5.41it/s]\n100%|██████████| 391/391 [01:11<00:00,  5.48it/s]\n100%|██████████| 625/625 [01:54<00:00,  5.47it/s]\n100%|██████████| 782/782 [02:22<00:00,  5.48it/s]\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"torch.save(test_image_feature, \"/kaggle/working/test_image_feature.pt\")\ntorch.save(test_image_label, \"/kaggle/working/test_image_label.pt\")\n\ntorch.save(client1_image_feature, \"/kaggle/working/client1_image_feature.pt\")\ntorch.save(client1_image_label, \"/kaggle/working/client1_image_label.pt\")\n\ntorch.save(client2_image_feature, \"/kaggle/working/client2_image_feature.pt\")\ntorch.save(client2_image_label, \"/kaggle/working/client2_image_label.pt\")\n\ntorch.save(client3_image_feature, \"/kaggle/working/client3_image_feature.pt\")\ntorch.save(client3_image_label, \"/kaggle/working/client3_image_label.pt\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T17:15:54.802449Z","iopub.execute_input":"2024-12-05T17:15:54.802913Z","iopub.status.idle":"2024-12-05T17:15:55.866266Z","shell.execute_reply.started":"2024-12-05T17:15:54.802871Z","shell.execute_reply":"2024-12-05T17:15:55.865554Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"test_image_feature = torch.load( \"/kaggle/working/test_image_feature.pt\" , weights_only = True)\ntest_image_label = torch.load( \"/kaggle/working/test_image_label.pt\", weights_only = True)\ntrain_image_feature = torch.load( \"/kaggle/working/client3_image_feature.pt\", weights_only = True)\ntrain_image_label = torch.load( \"/kaggle/working/client3_image_label.pt\", weights_only = True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T17:15:55.867256Z","iopub.execute_input":"2024-12-05T17:15:55.867530Z","iopub.status.idle":"2024-12-05T17:15:56.205592Z","shell.execute_reply.started":"2024-12-05T17:15:55.867503Z","shell.execute_reply":"2024-12-05T17:15:56.204613Z"}},"outputs":[],"execution_count":11},{"cell_type":"markdown","source":"# Softmax Model","metadata":{}},{"cell_type":"code","source":"# Define the Softmax Regression Model\nclass SoftmaxRegression(nn.Module):\n    def __init__(self, input_dim, num_classes):\n        super(SoftmaxRegression, self).__init__()\n        self.linear = nn.Linear(input_dim, num_classes)\n\n    def forward(self, x):\n        return self.linear(x)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T17:24:41.258110Z","iopub.execute_input":"2024-12-05T17:24:41.258417Z","iopub.status.idle":"2024-12-05T17:24:41.263364Z","shell.execute_reply.started":"2024-12-05T17:24:41.258390Z","shell.execute_reply":"2024-12-05T17:24:41.262386Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"# Initialize the model\ninput_dim = train_image_feature.size(1)  # Number of input features\nmodel = SoftmaxRegression(input_dim, 10).to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T17:24:41.495093Z","iopub.execute_input":"2024-12-05T17:24:41.495407Z","iopub.status.idle":"2024-12-05T17:24:41.500185Z","shell.execute_reply.started":"2024-12-05T17:24:41.495378Z","shell.execute_reply":"2024-12-05T17:24:41.499404Z"}},"outputs":[],"execution_count":27},{"cell_type":"code","source":"# Define loss function and optimizer\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-3)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T17:24:41.709724Z","iopub.execute_input":"2024-12-05T17:24:41.710015Z","iopub.status.idle":"2024-12-05T17:24:41.714508Z","shell.execute_reply.started":"2024-12-05T17:24:41.709991Z","shell.execute_reply":"2024-12-05T17:24:41.713599Z"}},"outputs":[],"execution_count":28},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom sklearn.metrics import accuracy_score\nimport torchvision\n\n# Split dataset into training and validation sets\n#labels = torch.tensor(train_dataset.targets)  # CIFAR-10 labels are integers 0-9\nX_train, X_val, y_train, y_val = train_test_split(\n    train_image_feature, train_image_label, test_size=0.2, random_state=42\n)\n#X_train, y_train, X_val, y_val = train_image_feature , train_image_label , test_image_feature, test_image_label\n# Create PyTorch Datasets and DataLoaders\ntrain_dataset = TensorDataset(X_train, y_train)\nval_dataset = TensorDataset(X_val, y_val)\n\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n\ntest_dataset =  TensorDataset(test_image_feature, test_image_label)\ntest_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T17:24:41.931149Z","iopub.execute_input":"2024-12-05T17:24:41.931412Z","iopub.status.idle":"2024-12-05T17:24:42.166406Z","shell.execute_reply.started":"2024-12-05T17:24:41.931387Z","shell.execute_reply":"2024-12-05T17:24:42.165597Z"}},"outputs":[],"execution_count":29},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Training Loop\nfor epoch in range(num_epochs):\n    model.train()\n    for X_batch, y_batch in train_loader:\n        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n\n        # Forward pass\n        outputs = model(X_batch)\n        loss = criterion(outputs, y_batch )\n\n        # Backward pass and optimization\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n    # Validation\n    model.eval()\n    val_predictions, val_labels = [], []\n    with torch.no_grad():\n        for X_batch, y_batch in val_loader:\n            X_batch = X_batch.to(device)\n            outputs = model(X_batch)\n            _, predicted = torch.max(outputs, 1)\n            val_predictions.extend(predicted.cpu().numpy())\n            val_labels.extend(y_batch.numpy())\n\n    # Calculate validation accuracy\n    val_accuracy = accuracy_score(val_labels, val_predictions)\n    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}, Validation Accuracy: {val_accuracy:.4f}\")\n\nprint(\"Training Complete.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T17:24:43.154249Z","iopub.execute_input":"2024-12-05T17:24:43.155209Z","iopub.status.idle":"2024-12-05T17:24:55.243157Z","shell.execute_reply.started":"2024-12-05T17:24:43.155170Z","shell.execute_reply":"2024-12-05T17:24:55.242104Z"}},"outputs":[{"name":"stdout","text":"Epoch [1/10], Loss: 0.4077, Validation Accuracy: 0.8763\nEpoch [2/10], Loss: 0.4238, Validation Accuracy: 0.8878\nEpoch [3/10], Loss: 0.4363, Validation Accuracy: 0.8992\nEpoch [4/10], Loss: 0.3741, Validation Accuracy: 0.9007\nEpoch [5/10], Loss: 0.2617, Validation Accuracy: 0.9016\nEpoch [6/10], Loss: 0.3068, Validation Accuracy: 0.9062\nEpoch [7/10], Loss: 0.2046, Validation Accuracy: 0.9030\nEpoch [8/10], Loss: 0.1271, Validation Accuracy: 0.9040\nEpoch [9/10], Loss: 0.4109, Validation Accuracy: 0.8988\nEpoch [10/10], Loss: 0.2647, Validation Accuracy: 0.8937\nTraining Complete.\n","output_type":"stream"}],"execution_count":30},{"cell_type":"code","source":"model.eval()\nval_predictions, val_labels = [], []\nwith torch.no_grad():\n    for X_batch, y_batch in test_loader:\n        X_batch = X_batch.to(device)\n        outputs = model(X_batch)\n        _, predicted = torch.max(outputs, 1)\n        val_predictions.extend(predicted.cpu().numpy())\n        val_labels.extend(y_batch.numpy())\n\n# Calculate validation accuracy\nval_accuracy = accuracy_score(val_labels, val_predictions)\nprint(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}, Validation Accuracy: {val_accuracy:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T17:24:55.244440Z","iopub.execute_input":"2024-12-05T17:24:55.244759Z","iopub.status.idle":"2024-12-05T17:24:55.403130Z","shell.execute_reply.started":"2024-12-05T17:24:55.244729Z","shell.execute_reply":"2024-12-05T17:24:55.402255Z"}},"outputs":[{"name":"stdout","text":"Epoch [10/10], Loss: 0.2647, Validation Accuracy: 0.8871\n","output_type":"stream"}],"execution_count":31},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}